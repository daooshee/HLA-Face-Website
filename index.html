<!DOCTYPE HTML>
<html class="no-js">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
    <title>HLA-Face</title>
    <meta name="description" content="Lithium Description" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <link href="css/plugins.css" media="screen" rel="stylesheet" type="text/css" />
    <link href="css/application.css" media="screen" rel="stylesheet" type="text/css" />
  </head>

<body>

    <!-- ABOUT -->

    <section id="page-about" class="section">
      <div align="center" style="padding-bottom: 100px;">
        <p class="copy-02">CVPR 2021</p>
        <p class="heading h-01">HLA-Face: Joint High-Low Adaptation <br>for Low Light Face Detection</p>

        <p class="copy-02">
          <a href="https://daooshee.github.io/website/">Wenjing Wang</a> &nbsp;&nbsp;&nbsp;
          <a href="https://flyywh.github.io/">Wenhan Yang</a> &nbsp;&nbsp;&nbsp;
          <a href="https://www.icst.pku.edu.cn/struct/people/liujiaying.html">Jiaying Liu</a>
        </p>
      </div>

      <div class="site-inner">
        <h3 class="heading h-03">Abstract</h3>
        <div class="columns">
          <aside>
            <p class="copy-02">Face detection in low light scenarios is challenging but vital to many practical applications, e.g., surveillance video, autonomous driving at night. Most existing face detectors heavily rely on extensive annotations, while collecting data is time-consuming and laborious. To reduce the burden of building new datasets for low light conditions, we make full use of existing normal light data and explore how to adapt face detectors from normal light to low light. The challenge of this task is that the gap between normal and low light is too huge and complex for both pixel-level and object-level. Therefore, most existing low-light enhancement and adaptation methods do not achieve desirable performance. To address the issue, we propose a joint High-Low Adaptation (HLA) framework. Through a bidirectional low-level adaptation and multi-task high-level adaptation scheme, our HLA-Face outperforms state-of-the-art methods even without using dark face labels for training.</p>
          </aside>
          <aside>
            <div align="center" style="padding-bottom:10px">
              <img src="teasor.jpg" width=100%> <br>
            </div>
            <p class='copy-02' style="color:#888888">Dark face detection visual results and our learning paradigm. Compared with the result of DSFD [1] on original low light images and the enhanced version by LIME [2], our method can better recognize the faces in dark scenarios.
            </p>
          </aside>
        </div>
      </div>

      <div class="site-inner" style="padding-top: 50px;">
        <h3 class="heading h-03">Method</h3>
        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="motivation.jpg" width=90%> <br>
        </div>

        <p class='copy-02'>Motivation: comparison of different adaptive low light detection techniques. L: low light data. H: normal light data. Existing enhancement-based, darkening-based, and feature adaptation methods either ignore the high-level gap, or have limited effects due to the huge and complex gap between L and H. Our method instead considers both low-level and high-level adaptation, therefore achieves better performance.
        </p>

        <br><br>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="framework_2.jpg" width=70%> <br>
        </div>

        <p class='copy-02'>Framework: <a style="color:#4C6E8B"><b>LOW-LEVEL</b></a> adaptation fills the gap by creating intermediate states. We bidirectionally brighten the low light data as well as distort the normal light data with noise and color bias. Based on the built intermediate states, we use multi-task cross-domain self-supervised learning to fill the <a style="color:#85937E"><b>HIGH-LEVEL</b></a> gap.
        </p>
      </div>

      <div class="site-inner" style="padding-top: 50px;">
        <h3 class="heading h-03">Selected Experimental Results</h3>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="comp_map.jpg" width=60%> <br>
        </div>

        <div align="center">
          <p class='copy-02'>Precision-Recall (PR) curves on DARK FACE.
          </p>
        </div>

        <br><br>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="enh_comp.jpg" width=90%> <br>
        </div>



        <p class='copy-02'>Qualitative comparison of different enhancement-based methods. (a) Input low light image and the ground truth boxes. (b)-(g) Results of low-light enhancement methods with DSFD [1]. (h) Our result.
        </p>

      </div>



      <div class="site-inner" style="padding-top:50px;">
        <p class="heading h-03"> Resources </p> 
          <ul style="line-height:1.5; padding-left: 50px; padding-right: 50px">
          　　<li class="copy-02"> Paper: <a href="https://arxiv.org/abs/2104.01984">arXiv</a></li>
          　　<li class="copy-02"> Code: <a href="https://github.com/daooshee/HLA-Face-Code">Github</a></li>
          　　<li class="copy-02"> Supplementary Material: <a href="https://github.com/daooshee/HLA-Face-Code/blob/main/Supplementary%20Material.pdf">PDF</a></li>
          </ul>
      </div>
      

      <div class="site-inner" style="padding-top:50px;">
        <p class='heading h-03'> Citation</p>
        <p class="copy-02"> @InProceedings{HLAFace_2021_CVPR, <br>
        &nbsp; &nbsp; author = {Wang, Wenjing and Yang, Wenhan and Liu, Jiaying}, <br>
        &nbsp; &nbsp; title = {HLA-Face: Joint High-Low Adaptation for Low Light Face Detection}, <br>
        &nbsp; &nbsp; booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, <br>
        &nbsp; &nbsp; month = {June}, <br>
        &nbsp; &nbsp; year = {2021} <br>
        } <br> 
        </p>
      </div>

      <div class="site-inner" style="padding-top:50px;">
        <p class="heading h-03"> Resources </p> 
          <p class="copy-02"> [1] Jian Li, Yabiao Wang, Changan Wang, Ying Tai, Jianjun Qian, Jian Yang, Chengjie Wang, Jilin Li, Feiyue Huang: DSFD: Dual Shot Face Detector. CVPR 2019: 5060-5069</p>
          <br>
          <p class="copy-02"> [2] Xiaojie Guo, Yu Li, Haibin Ling: LIME: Low-Light Image Enhancement via Illumination Map Estimation. IEEE Trans. Image Process. 26(2): 982-993 (2017)</p>
      </div>

    <section id="page-about" class="section">

</body>
</html>
